{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install python-pptx"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hu_ZyUXINL1c",
        "outputId": "ecf0a313-45de-4d8e-cacd-8cf57526ec39"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-pptx\n",
            "  Downloading python_pptx-1.0.2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: Pillow>=3.3.2 in /usr/local/lib/python3.12/dist-packages (from python-pptx) (11.3.0)\n",
            "Collecting XlsxWriter>=0.5.7 (from python-pptx)\n",
            "  Downloading xlsxwriter-3.2.5-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from python-pptx) (5.4.0)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.12/dist-packages (from python-pptx) (4.14.1)\n",
            "Downloading python_pptx-1.0.2-py3-none-any.whl (472 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.8/472.8 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xlsxwriter-3.2.5-py3-none-any.whl (172 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.3/172.3 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: XlsxWriter, python-pptx\n",
            "Successfully installed XlsxWriter-3.2.5 python-pptx-1.0.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os, io\n",
        "from datetime import datetime\n",
        "from collections import OrderedDict\n",
        "\n",
        "def clean_col(c):\n",
        "    return (\n",
        "        str(c)\n",
        "        .strip()\n",
        "        .lower()\n",
        "        .replace(\" \", \"_\")\n",
        "        .replace(\"-\", \"_\")\n",
        "        .replace(\"/\", \"_\")\n",
        "        .replace(\".\", \"_\")\n",
        "    )\n",
        "\n",
        "def first_present(keys, columns):\n",
        "    for k in keys:\n",
        "        if k in columns:\n",
        "            return k\n",
        "    return None\n",
        "\n",
        "def load_data(path):\n",
        "    for enc in [\"utf-8-sig\", \"cp1252\", \"latin1\"]:\n",
        "        try:\n",
        "            df = pd.read_csv(path, encoding=enc, engine=\"python\", on_bad_lines=\"skip\")\n",
        "            return df, enc\n",
        "        except Exception:\n",
        "            continue\n",
        "    raise RuntimeError(\"Failed to read CSV with common encodings.\")\n",
        "\n",
        "def main(csv_path, out_dir=\"analysis_outputs\"):\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "    df, enc = load_data(csv_path)\n",
        "    original_columns = df.columns.tolist()\n",
        "    df.columns = [clean_col(c) for c in df.columns]\n",
        "\n",
        "    # Parse date columns\n",
        "    date_cols_guess = [c for c in df.columns if \"date\" in c]\n",
        "    for c in date_cols_guess:\n",
        "        try:\n",
        "            df[c] = pd.to_datetime(df[c], errors=\"coerce\", infer_datetime_format=True, dayfirst=False)\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    # Normalize money & quantities\n",
        "    money_like = [c for c in df.columns if any(k in c for k in [\"amount\",\"price\",\"revenue\",\"sales\",\"total\"])]\n",
        "    for c in money_like:\n",
        "        if df[c].dtype == object:\n",
        "            df[c] = (\n",
        "                df[c].astype(str)\n",
        "                .str.replace(\",\", \"\", regex=False)\n",
        "                .str.replace(\"₹\", \"\", regex=False)\n",
        "                .str.replace(\"$\", \"\", regex=False)\n",
        "                .str.replace(\" \", \"\", regex=False)\n",
        "                .str.replace(\"INR\", \"\", regex=False)\n",
        "            )\n",
        "            df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
        "\n",
        "    qty_cols = [c for c in df.columns if c in [\"qty\",\"quantity\",\"order_quantity\",\"units\",\"unit\"] or \"qty\" in c]\n",
        "    for c in qty_cols:\n",
        "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
        "\n",
        "    # Column schema mapping\n",
        "    colmap = {\n",
        "        \"order_id\": [ \"order_id\",\"orderid\",\"order_item_id\",\"order_item\",\"order_item_identifier\"],\n",
        "        \"order_date\": [\"order_date\",\"date\",\"purchase_date\",\"order_date_time\"],\n",
        "        \"status\": [\"status\",\"order_status\"],\n",
        "        \"fulfilment\": [\"fulfilment\",\"fulfillment\",\"fulfillment_channel\",\"fulfilled_by\"],\n",
        "        \"sales_channel\": [\"sales_channel\",\"saleschannel\",\"channel\"],\n",
        "        \"category\": [\"category\",\"product_category\",\"product_type\"],\n",
        "        \"size\": [\"size\",\"variant\",\"product_size\"],\n",
        "        \"qty\": [\"qty\",\"quantity\",\"units\",\"order_quantity\"],\n",
        "        \"amount\": [\"amount\",\"item_total\",\"total\",\"grand_total\",\"net_amount\",\"order_amount\",\"sales\"],\n",
        "        \"ship_city\": [\"ship_city\",\"ship_city_name\",\"city\"],\n",
        "        \"ship_state\": [\"ship_state\",\"state\"],\n",
        "        \"ship_postal_code\": [\"ship_postal_code\",\"postal_code\",\"pincode\",\"zip\"],\n",
        "        \"courier_status\": [\"courier_status\",\"shipment_status\",\"shipping_status\"],\n",
        "        \"fulfilled_on\": [\"fulfilled_on\",\"dispatch_date\",\"ship_date\"],\n",
        "    }\n",
        "    schema = {k:first_present(v, df.columns) for k,v in colmap.items()}\n",
        "\n",
        "    ORDER_ID = schema[\"order_id\"]\n",
        "    ORDER_DATE = schema[\"order_date\"]\n",
        "    STATUS = schema[\"status\"]\n",
        "    FULFIL = schema[\"fulfilment\"]\n",
        "    CHANNEL = schema[\"sales_channel\"]\n",
        "    CAT = schema[\"category\"]\n",
        "    SIZE = schema[\"size\"]\n",
        "    QTY = schema[\"qty\"]\n",
        "    AMT = schema[\"amount\"]\n",
        "    CITY = schema[\"ship_city\"]\n",
        "    STATE = schema[\"ship_state\"]\n",
        "\n",
        "    # KPIs\n",
        "    kpi = OrderedDict()\n",
        "    kpi[\"used_encoding\"] = enc\n",
        "    kpi[\"total_rows\"] = len(df)\n",
        "    kpi[\"columns_detected\"] = \", \".join(df.columns)\n",
        "    kpi[\"total_revenue\"] = float(np.nansum(df[AMT])) if AMT else np.nan\n",
        "    kpi[\"avg_order_value\"] = float(np.nanmean(df[AMT])) if AMT else np.nan\n",
        "    kpi[\"total_units\"] = int(np.nansum(df[QTY])) if QTY else np.nan\n",
        "    kpi[\"total_orders\"] = df[ORDER_ID].nunique() if ORDER_ID else np.nan\n",
        "\n",
        "    # Time series\n",
        "    timeseries = None\n",
        "    if ORDER_DATE:\n",
        "        ts = df.dropna(subset=[ORDER_DATE]).copy()\n",
        "        ts[\"year_month\"] = ts[ORDER_DATE].dt.to_period(\"M\").dt.to_timestamp()\n",
        "        agg_map = {}\n",
        "        if AMT: agg_map[AMT] = \"sum\"\n",
        "        if QTY: agg_map[QTY] = \"sum\"\n",
        "        if ORDER_ID: agg_map[ORDER_ID] = pd.Series.nunique\n",
        "        if agg_map:\n",
        "            timeseries = ts.groupby([\"year_month\"]).agg(agg_map).reset_index().sort_values(\"year_month\")\n",
        "\n",
        "    # Category analysis\n",
        "    top_categories_sales = (df.groupby(CAT)[AMT].sum().sort_values(ascending=False).head(10).reset_index()) if CAT and AMT else None\n",
        "    top_categories_units = (df.groupby(CAT)[QTY].sum().sort_values(ascending=False).head(10).reset_index()) if CAT and QTY else None\n",
        "\n",
        "    # Size analysis\n",
        "    size_summary = None\n",
        "    if SIZE:\n",
        "        agg_map = {}\n",
        "        if AMT: agg_map[AMT] = \"sum\"\n",
        "        if QTY: agg_map[QTY] = \"sum\"\n",
        "        if agg_map:\n",
        "            size_summary = df.groupby(SIZE).agg(agg_map).sort_values(list(agg_map.keys())[0], ascending=False).reset_index()\n",
        "\n",
        "    # Fulfilment & Status\n",
        "    fulfil_summary = None\n",
        "    if FULFIL:\n",
        "        fulfil_summary = df.groupby(FULFIL).size().reset_index(name=\"orders\")\n",
        "        if AMT: fulfil_summary = fulfil_summary.merge(df.groupby(FULFIL)[AMT].sum().reset_index(name=\"sales_amount\"), on=FULFIL, how=\"left\")\n",
        "        if QTY: fulfil_summary = fulfil_summary.merge(df.groupby(FULFIL)[QTY].sum().reset_index(name=\"units\"), on=FULFIL, how=\"left\")\n",
        "\n",
        "    status_summary = None\n",
        "    if STATUS:\n",
        "        status_summary = df.groupby(STATUS).size().reset_index(name=\"orders\")\n",
        "        if AMT: status_summary = status_summary.merge(df.groupby(STATUS)[AMT].sum().reset_index(name=\"sales_amount\"), on=STATUS, how=\"left\")\n",
        "\n",
        "    # Geography\n",
        "    state_summary = (df.groupby(STATE)[AMT].sum().sort_values(ascending=False).reset_index()) if STATE and AMT else None\n",
        "    city_summary = (df.groupby(CITY)[AMT].sum().sort_values(ascending=False).reset_index()) if CITY and AMT else None\n",
        "\n",
        "    # Save CSVs\n",
        "    def save_df(d, name):\n",
        "        if d is None: return None\n",
        "        path = os.path.join(out_dir, f\"{name}.csv\")\n",
        "        d.to_csv(path, index=False)\n",
        "        return path\n",
        "\n",
        "    outputs = {\n",
        "        \"timeseries\": save_df(timeseries, \"timeseries_monthly\"),\n",
        "        \"top_categories_sales\": save_df(top_categories_sales, \"top_categories_by_sales\"),\n",
        "        \"top_categories_units\": save_df(top_categories_units, \"top_categories_by_units\"),\n",
        "        \"size_summary\": save_df(size_summary, \"size_summary\"),\n",
        "        \"fulfilment_summary\": save_df(fulfil_summary, \"fulfilment_summary\"),\n",
        "        \"status_summary\": save_df(status_summary, \"status_summary\"),\n",
        "        \"state_sales_summary\": save_df(state_summary, \"state_sales_summary\"),\n",
        "        \"city_sales_summary\": save_df(city_summary, \"city_sales_summary\"),\n",
        "    }\n",
        "\n",
        "    # Charts\n",
        "    def line_chart(df_, x, y, title, fname):\n",
        "        if df_ is None or df_.empty or x not in df_.columns or y not in df_.columns:\n",
        "            return None\n",
        "        fig = plt.figure()\n",
        "        plt.plot(df_[x], df_[y])\n",
        "        plt.title(title)\n",
        "        plt.xlabel(x.replace(\"_\",\" \").title())\n",
        "        plt.ylabel(y.replace(\"_\",\" \").title())\n",
        "        plt.xticks(rotation=45, ha=\"right\")\n",
        "        plt.tight_layout()\n",
        "        fpath = os.path.join(out_dir, fname)\n",
        "        plt.savefig(fpath, dpi=150, bbox_inches=\"tight\")\n",
        "        plt.close(fig)\n",
        "        return fpath\n",
        "\n",
        "    def bar_chart(df_, x, y, title, fname, topn=None):\n",
        "        if df_ is None or df_.empty or x not in df_.columns or y not in df_.columns:\n",
        "            return None\n",
        "        data = df_.copy()\n",
        "        if topn is not None:\n",
        "            data = data.head(topn)\n",
        "        fig = plt.figure()\n",
        "        plt.bar(data[x].astype(str), data[y])\n",
        "        plt.title(title)\n",
        "        plt.xlabel(x.replace(\"_\",\" \").title())\n",
        "        plt.ylabel(y.replace(\"_\",\" \").title())\n",
        "        plt.xticks(rotation=45, ha=\"right\")\n",
        "        plt.tight_layout()\n",
        "        fpath = os.path.join(out_dir, fname)\n",
        "        plt.savefig(fpath, dpi=150, bbox_inches=\"tight\")\n",
        "        plt.close(fig)\n",
        "        return fpath\n",
        "\n",
        "    charts = {}\n",
        "    if timeseries is not None and AMT in timeseries.columns:\n",
        "        charts[\"chart_monthly_revenue.png\"] = line_chart(timeseries, \"year_month\", AMT, \"Monthly Revenue Trend\", \"chart_monthly_revenue.png\")\n",
        "    if timeseries is not None and QTY and QTY in timeseries.columns:\n",
        "        charts[\"chart_monthly_units.png\"] = line_chart(timeseries, \"year_month\", QTY, \"Monthly Units Trend\", \"chart_monthly_units.png\")\n",
        "    if top_categories_sales is not None:\n",
        "        charts[\"chart_top_categories_sales.png\"] = bar_chart(top_categories_sales, CAT, AMT, \"Top Categories by Sales\", \"chart_top_categories_sales.png\", topn=10)\n",
        "    if top_categories_units is not None:\n",
        "        charts[\"chart_top_categories_units.png\"] = bar_chart(top_categories_units, CAT, QTY, \"Top Categories by Units\", \"chart_top_categories_units.png\", topn=10)\n",
        "    if size_summary is not None and AMT in size_summary.columns:\n",
        "        charts[\"chart_sales_by_size.png\"] = bar_chart(size_summary, SIZE, AMT, \"Sales by Size/Variant\", \"chart_sales_by_size.png\", topn=15)\n",
        "    if fulfil_summary is not None:\n",
        "        if \"orders\" in fulfil_summary.columns:\n",
        "            charts[\"chart_orders_by_fulfilment.png\"] = bar_chart(fulfil_summary.sort_values(\"orders\", ascending=False), FULFIL, \"orders\", \"Orders by Fulfilment Method\", \"chart_orders_by_fulfilment.png\")\n",
        "        if AMT and AMT in fulfil_summary.columns:\n",
        "            charts[\"chart_sales_by_fulfilment.png\"] = bar_chart(fulfil_summary.sort_values(\"sales_amount\", ascending=False), FULFIL, \"sales_amount\", \"Sales by Fulfilment Method\", \"chart_sales_by_fulfilment.png\")\n",
        "    if state_summary is not None and STATE in state_summary.columns:\n",
        "        charts[\"chart_top_states_by_sales.png\"] = bar_chart(state_summary.head(15), STATE, AMT, \"Top States by Sales\", \"chart_top_states_by_sales.png\")\n",
        "    if city_summary is not None and CITY in city_summary.columns:\n",
        "        charts[\"chart_top_cities_by_sales.png\"] = bar_chart(city_summary.head(15), CITY, AMT, \"Top Cities by Sales\", \"chart_top_cities_by_sales.png\")\n",
        "\n",
        "    # PowerPoint\n",
        "    pptx_path = None\n",
        "    try:\n",
        "        from pptx import Presentation\n",
        "        from pptx.util import Inches, Pt\n",
        "        from pptx.enum.text import MSO_ANCHOR, MSO_AUTO_SIZE\n",
        "\n",
        "        prs = Presentation()\n",
        "        slide_layout_title = prs.slide_layouts[0]\n",
        "        slide_title = prs.slides.add_slide(slide_layout_title)\n",
        "        slide_title.shapes.title.text = \"Amazon Sales Analysis\"\n",
        "        slide_title.placeholders[1].text = f\"Generated on {datetime.now():%Y-%m-%d %H:%M}\"\n",
        "\n",
        "        # Use a blank slide layout for KPIs and add a textbox\n",
        "        slide_layout_blank = prs.slide_layouts[6] # Use a blank layout\n",
        "        slide_kpis = prs.slides.add_slide(slide_layout_blank)\n",
        "\n",
        "        # Add title as a textbox\n",
        "        left, top, width, height = Inches(1), Inches(0.5), Inches(8), Inches(1)\n",
        "        title_box = slide_kpis.shapes.add_textbox(left, top, width, height)\n",
        "        title_frame = title_box.text_frame\n",
        "        title_p = title_frame.add_paragraph()\n",
        "        title_p.text = \"Executive KPIs\"\n",
        "        title_p.font.size = Pt(24) # Adjust font size for title\n",
        "\n",
        "        left, top, width, height = Inches(1), Inches(1.5), Inches(8), Inches(5)\n",
        "        txBox = slide_kpis.shapes.add_textbox(left, top, width, height)\n",
        "        tf = txBox.text_frame\n",
        "        tf.clear()\n",
        "\n",
        "        for k,v in OrderedDict(kpi).items():\n",
        "            p = tf.add_paragraph()\n",
        "            vfmt = f\"{v:,.2f}\" if isinstance(v,(int,float)) and not pd.isna(v) else str(v)\n",
        "            p.text = f\"{k.replace('_',' ').title()}: {vfmt}\"\n",
        "            p.font.size = Pt(14) # Adjust font size if needed\n",
        "\n",
        "        for title, path in charts.items():\n",
        "            if path and os.path.exists(path):\n",
        "                slide = prs.slides.add_slide(prs.slide_layouts[5])\n",
        "                slide.shapes.title.text = title.replace(\"_\",\" \").replace(\".png\",\"\").title()\n",
        "                slide.shapes.add_picture(path, Inches(0.5), Inches(1.5), height=Inches(5))\n",
        "\n",
        "        pptx_path = os.path.join(out_dir, \"Amazon_Sales_Analysis_Report.pptx\")\n",
        "        prs.save(pptx_path)\n",
        "    except ImportError:\n",
        "         print(\"Python-pptx library not found. Skipping PowerPoint generation.\")\n",
        "         pptx_path = None\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating PowerPoint: {e}\")\n",
        "        pptx_path = None\n",
        "\n",
        "\n",
        "    # Text summary\n",
        "    with open(os.path.join(out_dir, \"analysis_summary.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(\"Amazon Sales Analysis – Auto Summary\\n\")\n",
        "        f.write(f\"Generated: {datetime.now()}\\n\\n\")\n",
        "        f.write(\"Detected Columns:\\n\")\n",
        "        f.write(\", \".join(df.columns) + \"\\n\\n\")\n",
        "        f.write(\"Key Performance Indicators:\\n\")\n",
        "        for k,v in kpi.items():\n",
        "            vfmt = f\"{v:,.2f}\" if isinstance(v,(int,float)) and not pd.isna(v) else str(v)\n",
        "            f.write(f\"- {k.replace('_',' ').title()}: {vfmt}\\n\")\n",
        "\n",
        "    return {\n",
        "        \"outputs\": outputs,\n",
        "        \"charts\": charts,\n",
        "        \"pptx_path\": pptx_path,\n",
        "        \"kpi\": kpi,\n",
        "        \"schema\": schema,\n",
        "        \"original_columns\": original_columns,\n",
        "        \"standardized_columns\": df.columns.tolist(),\n",
        "    }\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     import argparse\n",
        "#     parser = argparse.ArgumentParser()\n",
        "#     parser.add_argument(\"--csv\", required=True, help=\"Path to Amazon Sale Report CSV\")\n",
        "#     parser.add_argument(\"--out\", default=\"analysis_outputs\", help=\"Output directory\")\n",
        "#     args = parser.parse_args()\n",
        "#     res = main(args.csv, args.out)\n",
        "#     print(\"Analysis complete. Outputs:\", res[\"outputs\"])\n",
        "#     print(\"Charts:\", res[\"charts\"])\n",
        "#     print(\"PPTX:\", res[\"pptx_path\"])\n",
        "\n",
        "# Call the main function directly with the CSV file path\n",
        "csv_file_path = \"/content/Amazon Sale Report.csv\"\n",
        "output_directory = \"analysis_outputs\"\n",
        "res = main(csv_file_path, output_directory)\n",
        "print(\"Analysis complete. Outputs:\", res[\"outputs\"])\n",
        "print(\"Charts:\", res[\"charts\"])\n",
        "print(\"PPTX:\", res[\"pptx_path\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oM5JZl8XRBcr",
        "outputId": "d1ec7f5f-fda8-4ae9-fc39-f7b0395c2772"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2834161124.py:45: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
            "  df[c] = pd.to_datetime(df[c], errors=\"coerce\", infer_datetime_format=True, dayfirst=False)\n",
            "/tmp/ipython-input-2834161124.py:45: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df[c] = pd.to_datetime(df[c], errors=\"coerce\", infer_datetime_format=True, dayfirst=False)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analysis complete. Outputs: {'timeseries': 'analysis_outputs/timeseries_monthly.csv', 'top_categories_sales': 'analysis_outputs/top_categories_by_sales.csv', 'top_categories_units': 'analysis_outputs/top_categories_by_units.csv', 'size_summary': 'analysis_outputs/size_summary.csv', 'fulfilment_summary': 'analysis_outputs/fulfilment_summary.csv', 'status_summary': 'analysis_outputs/status_summary.csv', 'state_sales_summary': 'analysis_outputs/state_sales_summary.csv', 'city_sales_summary': 'analysis_outputs/city_sales_summary.csv'}\n",
            "Charts: {'chart_monthly_revenue.png': 'analysis_outputs/chart_monthly_revenue.png', 'chart_monthly_units.png': 'analysis_outputs/chart_monthly_units.png', 'chart_top_categories_sales.png': 'analysis_outputs/chart_top_categories_sales.png', 'chart_top_categories_units.png': 'analysis_outputs/chart_top_categories_units.png', 'chart_sales_by_size.png': 'analysis_outputs/chart_sales_by_size.png', 'chart_orders_by_fulfilment.png': 'analysis_outputs/chart_orders_by_fulfilment.png', 'chart_top_states_by_sales.png': 'analysis_outputs/chart_top_states_by_sales.png', 'chart_top_cities_by_sales.png': 'analysis_outputs/chart_top_cities_by_sales.png'}\n",
            "PPTX: analysis_outputs/Amazon_Sales_Analysis_Report.pptx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Amazon Sales Analysis Report  \n",
        "\n",
        "**Student:** Aniruddha Shit\n",
        "**Project Title:** Amazon Sales Report Analysis  \n",
        "\n",
        "---\n",
        "\n",
        "## Key Objectives (from Task Brief)\n",
        "1. Sales Overview – Understand revenue, orders, units, and trends.  \n",
        "2. Product/Category Analysis – Identify top categories, variants, sizes.  \n",
        "3. Fulfilment Analysis – Compare fulfilment methods and order statuses.  \n",
        "4. Customer/Geographical Segmentation – Revenue contribution by city/state.  \n",
        "5. Business Insights & Recommendations – Suggest improvements.  \n",
        "\n",
        "---\n",
        "\n",
        "## Deliverables\n",
        "\n",
        "1. Comprehensive Analysis Report – Summarizing findings, insights, and recommendations.  \n",
        "2. Visualizations – Charts and graphs highlighting trends, categories, fulfilment, and geography.  \n",
        "3. Insights – Product preferences, customer behaviour, and geographical distribution.  \n",
        "4. Recommendations – For sales strategy, inventory, and customer service.  \n",
        "\n",
        "Files and outputs generated:  \n",
        "- PowerPoint: `Amazon_Sales_Analysis_Report.pptx`  \n",
        "- Summary Report: `analysis_summary.txt`  \n",
        "- CSV Files:  \n",
        "  - `timeseries_monthly.csv`  \n",
        "  - `top_categories_by_sales.csv`  \n",
        "  - `top_categories_by_units.csv`  \n",
        "  - `size_summary.csv`  \n",
        "  - `fulfilment_summary.csv`  \n",
        "  - `status_summary.csv`  \n",
        "  - `state_sales_summary.csv`  \n",
        "  - `city_sales_summary.csv`  \n",
        "- Charts: Embedded in PPT and also exported as separate PNG files.  \n",
        "\n",
        "---\n",
        "\n",
        "## Comprehensive Analysis\n",
        "\n",
        "### 1. Sales Overview and Performance Trends\n",
        "- KPIs Identified: Total revenue, total units sold, total unique orders, and average order value.  \n",
        "- Monthly Trends: Monthly revenue and unit sales reveal demand peaks and seasonal variations.  \n",
        "- Insight: Consistent growth in revenue during certain months suggests seasonal promotions or events drive higher sales.  \n",
        "\n",
        "### 2. Product and Category Analysis\n",
        "- Top Categories: Identified by revenue and units sold (`top_categories_by_sales.csv`, `top_categories_by_units.csv`).  \n",
        "- Size/Variant Preferences: Customers showed demand for specific sizes and product variants (`size_summary.csv`).  \n",
        "- Insight: Some categories contribute disproportionately to revenue, while others sell in volume at low margins.  \n",
        "\n",
        "### 3. Fulfilment and Status Analysis\n",
        "- Fulfilment: Orders and revenue compared across fulfilment channels (`fulfilment_summary.csv`).  \n",
        "- Status: Delivered, Cancelled, and Returned orders analysed (`status_summary.csv`).  \n",
        "- Insight: Fulfilment by Amazon may dominate sales, but cancellations and returns highlight areas for operational improvement.  \n",
        "\n",
        "### 4. Customer and Geographical Analysis\n",
        "- Regional Distribution: Sales mapped by state and city (`state_sales_summary.csv`, `city_sales_summary.csv`).  \n",
        "- Insight: Revenue is concentrated in a few top-performing states/cities. Regional differences suggest the need for localized strategies.  \n",
        "\n",
        "---\n",
        "\n",
        "## Insights on Customer Behaviour\n",
        "- Product Preferences: High demand for a few top categories and variants.  \n",
        "- Behavioural Trends: High cancellation and return rates in some categories may be linked to quality or fulfilment issues.  \n",
        "- Regional Behaviour: Strong markets exist in top 5 cities/states, while weaker regions present opportunities for expansion.  \n",
        "\n",
        "---\n",
        "\n",
        "## Recommendations\n",
        "\n",
        "1. Sales Strategy Improvements  \n",
        "   - Focus campaigns on top-performing categories.  \n",
        "   - Re-price or bundle low-margin, high-volume products to increase profitability.  \n",
        "\n",
        "2. Inventory Management  \n",
        "   - Align stock levels with geographical demand.  \n",
        "   - Address high-return categories by improving product information and quality control.  \n",
        "\n",
        "3. Customer Service Enhancements  \n",
        "   - Reduce cancellations by improving fulfilment accuracy and delivery times.  \n",
        "   - Enhance return handling and customer communication to maintain trust.  \n",
        "\n",
        "---\n",
        "\n",
        "## Expected Outcome Verification\n",
        "\n",
        "| Expected Outcome                     | Evidence Source                                                                     | Verified |\n",
        "|--------------------------------------|-------------------------------------------------------------------------------------|----------|\n",
        "| Sales trend and KPIs                 | PowerPoint (Executive KPIs, Monthly Revenue Trend), `analysis_summary.txt`          | Yes      |\n",
        "| Top categories and products           | `top_categories_by_sales.csv`, `top_categories_by_units.csv`, PowerPoint charts     | Yes      |\n",
        "| Fulfilment analysis                  | `fulfilment_summary.csv`, PowerPoint fulfilment charts                              | Yes      |\n",
        "| Order status performance             | `status_summary.csv`, PowerPoint chart Orders by Status                             | Yes      |\n",
        "| State and city contribution          | `state_sales_summary.csv`, `city_sales_summary.csv`, PowerPoint charts              | Yes      |\n",
        "| Insights and recommendations         | PowerPoint slides, `analysis_summary.txt`, written recommendations in this report   | Yes      |\n",
        "\n",
        "---\n",
        "\n",
        "## Additional Recommendations\n",
        "- RFM Segmentation: If customer IDs are available, segment customers by recency, frequency, and monetary value.  \n",
        "- Forecasting: Use monthly sales data to project demand and improve planning.  \n",
        "- Returns Analysis: Combine product category and status data to reduce return rates.  \n",
        "\n",
        "---\n",
        "\n",
        "## Conclusion\n",
        "This project delivers all required outputs: a detailed analysis report, visualization suite, insights into customer behaviour and geography, and actionable recommendations.  \n",
        "\n",
        "- Comprehensive analysis report explains findings in detail.  \n",
        "- Visualizations provide clear illustrations of trends and patterns.  \n",
        "- Insights highlight product preferences, customer behaviour, and geographical distribution.  \n",
        "- Recommendations propose concrete actions for sales strategies, inventory optimization, and customer service.  \n",
        "\n",
        "The analysis achieves the expected outcome of providing insights that can optimize operations, improve customer experience, and drive revenue growth.  \n"
      ],
      "metadata": {
        "id": "4RZB1bXcRNRf"
      }
    }
  ]
}