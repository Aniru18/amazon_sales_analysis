{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hu_ZyUXINL1c",
        "outputId": "ecf0a313-45de-4d8e-cacd-8cf57526ec39"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting python-pptx\n",
            "  Downloading python_pptx-1.0.2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: Pillow>=3.3.2 in /usr/local/lib/python3.12/dist-packages (from python-pptx) (11.3.0)\n",
            "Collecting XlsxWriter>=0.5.7 (from python-pptx)\n",
            "  Downloading xlsxwriter-3.2.5-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from python-pptx) (5.4.0)\n",
            "Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.12/dist-packages (from python-pptx) (4.14.1)\n",
            "Downloading python_pptx-1.0.2-py3-none-any.whl (472 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.8/472.8 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xlsxwriter-3.2.5-py3-none-any.whl (172 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.3/172.3 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: XlsxWriter, python-pptx\n",
            "Successfully installed XlsxWriter-3.2.5 python-pptx-1.0.2\n"
          ]
        }
      ],
      "source": [
        "!pip install python-pptx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oM5JZl8XRBcr",
        "outputId": "d1ec7f5f-fda8-4ae9-fc39-f7b0395c2772"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-2834161124.py:45: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
            "  df[c] = pd.to_datetime(df[c], errors=\"coerce\", infer_datetime_format=True, dayfirst=False)\n",
            "/tmp/ipython-input-2834161124.py:45: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df[c] = pd.to_datetime(df[c], errors=\"coerce\", infer_datetime_format=True, dayfirst=False)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Analysis complete. Outputs: {'timeseries': 'analysis_outputs/timeseries_monthly.csv', 'top_categories_sales': 'analysis_outputs/top_categories_by_sales.csv', 'top_categories_units': 'analysis_outputs/top_categories_by_units.csv', 'size_summary': 'analysis_outputs/size_summary.csv', 'fulfilment_summary': 'analysis_outputs/fulfilment_summary.csv', 'status_summary': 'analysis_outputs/status_summary.csv', 'state_sales_summary': 'analysis_outputs/state_sales_summary.csv', 'city_sales_summary': 'analysis_outputs/city_sales_summary.csv'}\n",
            "Charts: {'chart_monthly_revenue.png': 'analysis_outputs/chart_monthly_revenue.png', 'chart_monthly_units.png': 'analysis_outputs/chart_monthly_units.png', 'chart_top_categories_sales.png': 'analysis_outputs/chart_top_categories_sales.png', 'chart_top_categories_units.png': 'analysis_outputs/chart_top_categories_units.png', 'chart_sales_by_size.png': 'analysis_outputs/chart_sales_by_size.png', 'chart_orders_by_fulfilment.png': 'analysis_outputs/chart_orders_by_fulfilment.png', 'chart_top_states_by_sales.png': 'analysis_outputs/chart_top_states_by_sales.png', 'chart_top_cities_by_sales.png': 'analysis_outputs/chart_top_cities_by_sales.png'}\n",
            "PPTX: analysis_outputs/Amazon_Sales_Analysis_Report.pptx\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os, io\n",
        "from datetime import datetime\n",
        "from collections import OrderedDict\n",
        "\n",
        "def clean_col(c):\n",
        "    return (\n",
        "        str(c)\n",
        "        .strip()\n",
        "        .lower()\n",
        "        .replace(\" \", \"_\")\n",
        "        .replace(\"-\", \"_\")\n",
        "        .replace(\"/\", \"_\")\n",
        "        .replace(\".\", \"_\")\n",
        "    )\n",
        "\n",
        "def first_present(keys, columns):\n",
        "    for k in keys:\n",
        "        if k in columns:\n",
        "            return k\n",
        "    return None\n",
        "\n",
        "def load_data(path):\n",
        "    for enc in [\"utf-8-sig\", \"cp1252\", \"latin1\"]:\n",
        "        try:\n",
        "            df = pd.read_csv(path, encoding=enc, engine=\"python\", on_bad_lines=\"skip\")\n",
        "            return df, enc\n",
        "        except Exception:\n",
        "            continue\n",
        "    raise RuntimeError(\"Failed to read CSV with common encodings.\")\n",
        "\n",
        "def main(csv_path, out_dir=\"analysis_outputs\"):\n",
        "    os.makedirs(out_dir, exist_ok=True)\n",
        "\n",
        "    df, enc = load_data(csv_path)\n",
        "    original_columns = df.columns.tolist()\n",
        "    df.columns = [clean_col(c) for c in df.columns]\n",
        "\n",
        "    # Parse date columns\n",
        "    date_cols_guess = [c for c in df.columns if \"date\" in c]\n",
        "    for c in date_cols_guess:\n",
        "        try:\n",
        "            df[c] = pd.to_datetime(df[c], errors=\"coerce\", infer_datetime_format=True, dayfirst=False)\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    # Normalize money & quantities\n",
        "    money_like = [c for c in df.columns if any(k in c for k in [\"amount\",\"price\",\"revenue\",\"sales\",\"total\"])]\n",
        "    for c in money_like:\n",
        "        if df[c].dtype == object:\n",
        "            df[c] = (\n",
        "                df[c].astype(str)\n",
        "                .str.replace(\",\", \"\", regex=False)\n",
        "                .str.replace(\"₹\", \"\", regex=False)\n",
        "                .str.replace(\"$\", \"\", regex=False)\n",
        "                .str.replace(\" \", \"\", regex=False)\n",
        "                .str.replace(\"INR\", \"\", regex=False)\n",
        "            )\n",
        "            df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
        "\n",
        "    qty_cols = [c for c in df.columns if c in [\"qty\",\"quantity\",\"order_quantity\",\"units\",\"unit\"] or \"qty\" in c]\n",
        "    for c in qty_cols:\n",
        "        df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
        "\n",
        "    # Column schema mapping\n",
        "    colmap = {\n",
        "        \"order_id\": [ \"order_id\",\"orderid\",\"order_item_id\",\"order_item\",\"order_item_identifier\"],\n",
        "        \"order_date\": [\"order_date\",\"date\",\"purchase_date\",\"order_date_time\"],\n",
        "        \"status\": [\"status\",\"order_status\"],\n",
        "        \"fulfilment\": [\"fulfilment\",\"fulfillment\",\"fulfillment_channel\",\"fulfilled_by\"],\n",
        "        \"sales_channel\": [\"sales_channel\",\"saleschannel\",\"channel\"],\n",
        "        \"category\": [\"category\",\"product_category\",\"product_type\"],\n",
        "        \"size\": [\"size\",\"variant\",\"product_size\"],\n",
        "        \"qty\": [\"qty\",\"quantity\",\"units\",\"order_quantity\"],\n",
        "        \"amount\": [\"amount\",\"item_total\",\"total\",\"grand_total\",\"net_amount\",\"order_amount\",\"sales\"],\n",
        "        \"ship_city\": [\"ship_city\",\"ship_city_name\",\"city\"],\n",
        "        \"ship_state\": [\"ship_state\",\"state\"],\n",
        "        \"ship_postal_code\": [\"ship_postal_code\",\"postal_code\",\"pincode\",\"zip\"],\n",
        "        \"courier_status\": [\"courier_status\",\"shipment_status\",\"shipping_status\"],\n",
        "        \"fulfilled_on\": [\"fulfilled_on\",\"dispatch_date\",\"ship_date\"],\n",
        "    }\n",
        "    schema = {k:first_present(v, df.columns) for k,v in colmap.items()}\n",
        "\n",
        "    ORDER_ID = schema[\"order_id\"]\n",
        "    ORDER_DATE = schema[\"order_date\"]\n",
        "    STATUS = schema[\"status\"]\n",
        "    FULFIL = schema[\"fulfilment\"]\n",
        "    CHANNEL = schema[\"sales_channel\"]\n",
        "    CAT = schema[\"category\"]\n",
        "    SIZE = schema[\"size\"]\n",
        "    QTY = schema[\"qty\"]\n",
        "    AMT = schema[\"amount\"]\n",
        "    CITY = schema[\"ship_city\"]\n",
        "    STATE = schema[\"ship_state\"]\n",
        "\n",
        "    # KPIs\n",
        "    kpi = OrderedDict()\n",
        "    kpi[\"used_encoding\"] = enc\n",
        "    kpi[\"total_rows\"] = len(df)\n",
        "    kpi[\"columns_detected\"] = \", \".join(df.columns)\n",
        "    kpi[\"total_revenue\"] = float(np.nansum(df[AMT])) if AMT else np.nan\n",
        "    kpi[\"avg_order_value\"] = float(np.nanmean(df[AMT])) if AMT else np.nan\n",
        "    kpi[\"total_units\"] = int(np.nansum(df[QTY])) if QTY else np.nan\n",
        "    kpi[\"total_orders\"] = df[ORDER_ID].nunique() if ORDER_ID else np.nan\n",
        "\n",
        "    # Time series\n",
        "    timeseries = None\n",
        "    if ORDER_DATE:\n",
        "        ts = df.dropna(subset=[ORDER_DATE]).copy()\n",
        "        ts[\"year_month\"] = ts[ORDER_DATE].dt.to_period(\"M\").dt.to_timestamp()\n",
        "        agg_map = {}\n",
        "        if AMT: agg_map[AMT] = \"sum\"\n",
        "        if QTY: agg_map[QTY] = \"sum\"\n",
        "        if ORDER_ID: agg_map[ORDER_ID] = pd.Series.nunique\n",
        "        if agg_map:\n",
        "            timeseries = ts.groupby([\"year_month\"]).agg(agg_map).reset_index().sort_values(\"year_month\")\n",
        "\n",
        "    # Category analysis\n",
        "    top_categories_sales = (df.groupby(CAT)[AMT].sum().sort_values(ascending=False).head(10).reset_index()) if CAT and AMT else None\n",
        "    top_categories_units = (df.groupby(CAT)[QTY].sum().sort_values(ascending=False).head(10).reset_index()) if CAT and QTY else None\n",
        "\n",
        "    # Size analysis\n",
        "    size_summary = None\n",
        "    if SIZE:\n",
        "        agg_map = {}\n",
        "        if AMT: agg_map[AMT] = \"sum\"\n",
        "        if QTY: agg_map[QTY] = \"sum\"\n",
        "        if agg_map:\n",
        "            size_summary = df.groupby(SIZE).agg(agg_map).sort_values(list(agg_map.keys())[0], ascending=False).reset_index()\n",
        "\n",
        "    # Fulfilment & Status\n",
        "    fulfil_summary = None\n",
        "    if FULFIL:\n",
        "        fulfil_summary = df.groupby(FULFIL).size().reset_index(name=\"orders\")\n",
        "        if AMT: fulfil_summary = fulfil_summary.merge(df.groupby(FULFIL)[AMT].sum().reset_index(name=\"sales_amount\"), on=FULFIL, how=\"left\")\n",
        "        if QTY: fulfil_summary = fulfil_summary.merge(df.groupby(FULFIL)[QTY].sum().reset_index(name=\"units\"), on=FULFIL, how=\"left\")\n",
        "\n",
        "    status_summary = None\n",
        "    if STATUS:\n",
        "        status_summary = df.groupby(STATUS).size().reset_index(name=\"orders\")\n",
        "        if AMT: status_summary = status_summary.merge(df.groupby(STATUS)[AMT].sum().reset_index(name=\"sales_amount\"), on=STATUS, how=\"left\")\n",
        "\n",
        "    # Geography\n",
        "    state_summary = (df.groupby(STATE)[AMT].sum().sort_values(ascending=False).reset_index()) if STATE and AMT else None\n",
        "    city_summary = (df.groupby(CITY)[AMT].sum().sort_values(ascending=False).reset_index()) if CITY and AMT else None\n",
        "\n",
        "    # Save CSVs\n",
        "    def save_df(d, name):\n",
        "        if d is None: return None\n",
        "        path = os.path.join(out_dir, f\"{name}.csv\")\n",
        "        d.to_csv(path, index=False)\n",
        "        return path\n",
        "\n",
        "    outputs = {\n",
        "        \"timeseries\": save_df(timeseries, \"timeseries_monthly\"),\n",
        "        \"top_categories_sales\": save_df(top_categories_sales, \"top_categories_by_sales\"),\n",
        "        \"top_categories_units\": save_df(top_categories_units, \"top_categories_by_units\"),\n",
        "        \"size_summary\": save_df(size_summary, \"size_summary\"),\n",
        "        \"fulfilment_summary\": save_df(fulfil_summary, \"fulfilment_summary\"),\n",
        "        \"status_summary\": save_df(status_summary, \"status_summary\"),\n",
        "        \"state_sales_summary\": save_df(state_summary, \"state_sales_summary\"),\n",
        "        \"city_sales_summary\": save_df(city_summary, \"city_sales_summary\"),\n",
        "    }\n",
        "\n",
        "    # Charts\n",
        "    def line_chart(df_, x, y, title, fname):\n",
        "        if df_ is None or df_.empty or x not in df_.columns or y not in df_.columns:\n",
        "            return None\n",
        "        fig = plt.figure()\n",
        "        plt.plot(df_[x], df_[y])\n",
        "        plt.title(title)\n",
        "        plt.xlabel(x.replace(\"_\",\" \").title())\n",
        "        plt.ylabel(y.replace(\"_\",\" \").title())\n",
        "        plt.xticks(rotation=45, ha=\"right\")\n",
        "        plt.tight_layout()\n",
        "        fpath = os.path.join(out_dir, fname)\n",
        "        plt.savefig(fpath, dpi=150, bbox_inches=\"tight\")\n",
        "        plt.close(fig)\n",
        "        return fpath\n",
        "\n",
        "    def bar_chart(df_, x, y, title, fname, topn=None):\n",
        "        if df_ is None or df_.empty or x not in df_.columns or y not in df_.columns:\n",
        "            return None\n",
        "        data = df_.copy()\n",
        "        if topn is not None:\n",
        "            data = data.head(topn)\n",
        "        fig = plt.figure()\n",
        "        plt.bar(data[x].astype(str), data[y])\n",
        "        plt.title(title)\n",
        "        plt.xlabel(x.replace(\"_\",\" \").title())\n",
        "        plt.ylabel(y.replace(\"_\",\" \").title())\n",
        "        plt.xticks(rotation=45, ha=\"right\")\n",
        "        plt.tight_layout()\n",
        "        fpath = os.path.join(out_dir, fname)\n",
        "        plt.savefig(fpath, dpi=150, bbox_inches=\"tight\")\n",
        "        plt.close(fig)\n",
        "        return fpath\n",
        "\n",
        "    charts = {}\n",
        "    if timeseries is not None and AMT in timeseries.columns:\n",
        "        charts[\"chart_monthly_revenue.png\"] = line_chart(timeseries, \"year_month\", AMT, \"Monthly Revenue Trend\", \"chart_monthly_revenue.png\")\n",
        "    if timeseries is not None and QTY and QTY in timeseries.columns:\n",
        "        charts[\"chart_monthly_units.png\"] = line_chart(timeseries, \"year_month\", QTY, \"Monthly Units Trend\", \"chart_monthly_units.png\")\n",
        "    if top_categories_sales is not None:\n",
        "        charts[\"chart_top_categories_sales.png\"] = bar_chart(top_categories_sales, CAT, AMT, \"Top Categories by Sales\", \"chart_top_categories_sales.png\", topn=10)\n",
        "    if top_categories_units is not None:\n",
        "        charts[\"chart_top_categories_units.png\"] = bar_chart(top_categories_units, CAT, QTY, \"Top Categories by Units\", \"chart_top_categories_units.png\", topn=10)\n",
        "    if size_summary is not None and AMT in size_summary.columns:\n",
        "        charts[\"chart_sales_by_size.png\"] = bar_chart(size_summary, SIZE, AMT, \"Sales by Size/Variant\", \"chart_sales_by_size.png\", topn=15)\n",
        "    if fulfil_summary is not None:\n",
        "        if \"orders\" in fulfil_summary.columns:\n",
        "            charts[\"chart_orders_by_fulfilment.png\"] = bar_chart(fulfil_summary.sort_values(\"orders\", ascending=False), FULFIL, \"orders\", \"Orders by Fulfilment Method\", \"chart_orders_by_fulfilment.png\")\n",
        "        if AMT and AMT in fulfil_summary.columns:\n",
        "            charts[\"chart_sales_by_fulfilment.png\"] = bar_chart(fulfil_summary.sort_values(\"sales_amount\", ascending=False), FULFIL, \"sales_amount\", \"Sales by Fulfilment Method\", \"chart_sales_by_fulfilment.png\")\n",
        "    if state_summary is not None and STATE in state_summary.columns:\n",
        "        charts[\"chart_top_states_by_sales.png\"] = bar_chart(state_summary.head(15), STATE, AMT, \"Top States by Sales\", \"chart_top_states_by_sales.png\")\n",
        "    if city_summary is not None and CITY in city_summary.columns:\n",
        "        charts[\"chart_top_cities_by_sales.png\"] = bar_chart(city_summary.head(15), CITY, AMT, \"Top Cities by Sales\", \"chart_top_cities_by_sales.png\")\n",
        "\n",
        "    # PowerPoint\n",
        "    pptx_path = None\n",
        "    try:\n",
        "        from pptx import Presentation\n",
        "        from pptx.util import Inches, Pt\n",
        "        from pptx.enum.text import MSO_ANCHOR, MSO_AUTO_SIZE\n",
        "\n",
        "        prs = Presentation()\n",
        "        slide_layout_title = prs.slide_layouts[0]\n",
        "        slide_title = prs.slides.add_slide(slide_layout_title)\n",
        "        slide_title.shapes.title.text = \"Amazon Sales Analysis\"\n",
        "        slide_title.placeholders[1].text = f\"Generated on {datetime.now():%Y-%m-%d %H:%M}\"\n",
        "\n",
        "        # Use a blank slide layout for KPIs and add a textbox\n",
        "        slide_layout_blank = prs.slide_layouts[6] # Use a blank layout\n",
        "        slide_kpis = prs.slides.add_slide(slide_layout_blank)\n",
        "\n",
        "        # Add title as a textbox\n",
        "        left, top, width, height = Inches(1), Inches(0.5), Inches(8), Inches(1)\n",
        "        title_box = slide_kpis.shapes.add_textbox(left, top, width, height)\n",
        "        title_frame = title_box.text_frame\n",
        "        title_p = title_frame.add_paragraph()\n",
        "        title_p.text = \"Executive KPIs\"\n",
        "        title_p.font.size = Pt(24) # Adjust font size for title\n",
        "\n",
        "        left, top, width, height = Inches(1), Inches(1.5), Inches(8), Inches(5)\n",
        "        txBox = slide_kpis.shapes.add_textbox(left, top, width, height)\n",
        "        tf = txBox.text_frame\n",
        "        tf.clear()\n",
        "\n",
        "        for k,v in OrderedDict(kpi).items():\n",
        "            p = tf.add_paragraph()\n",
        "            vfmt = f\"{v:,.2f}\" if isinstance(v,(int,float)) and not pd.isna(v) else str(v)\n",
        "            p.text = f\"{k.replace('_',' ').title()}: {vfmt}\"\n",
        "            p.font.size = Pt(14) # Adjust font size if needed\n",
        "\n",
        "        for title, path in charts.items():\n",
        "            if path and os.path.exists(path):\n",
        "                slide = prs.slides.add_slide(prs.slide_layouts[5])\n",
        "                slide.shapes.title.text = title.replace(\"_\",\" \").replace(\".png\",\"\").title()\n",
        "                slide.shapes.add_picture(path, Inches(0.5), Inches(1.5), height=Inches(5))\n",
        "\n",
        "        pptx_path = os.path.join(out_dir, \"Amazon_Sales_Analysis_Report.pptx\")\n",
        "        prs.save(pptx_path)\n",
        "    except ImportError:\n",
        "         print(\"Python-pptx library not found. Skipping PowerPoint generation.\")\n",
        "         pptx_path = None\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating PowerPoint: {e}\")\n",
        "        pptx_path = None\n",
        "\n",
        "\n",
        "    # Text summary\n",
        "    with open(os.path.join(out_dir, \"analysis_summary.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
        "        f.write(\"Amazon Sales Analysis – Auto Summary\\n\")\n",
        "        f.write(f\"Generated: {datetime.now()}\\n\\n\")\n",
        "        f.write(\"Detected Columns:\\n\")\n",
        "        f.write(\", \".join(df.columns) + \"\\n\\n\")\n",
        "        f.write(\"Key Performance Indicators:\\n\")\n",
        "        for k,v in kpi.items():\n",
        "            vfmt = f\"{v:,.2f}\" if isinstance(v,(int,float)) and not pd.isna(v) else str(v)\n",
        "            f.write(f\"- {k.replace('_',' ').title()}: {vfmt}\\n\")\n",
        "\n",
        "    return {\n",
        "        \"outputs\": outputs,\n",
        "        \"charts\": charts,\n",
        "        \"pptx_path\": pptx_path,\n",
        "        \"kpi\": kpi,\n",
        "        \"schema\": schema,\n",
        "        \"original_columns\": original_columns,\n",
        "        \"standardized_columns\": df.columns.tolist(),\n",
        "    }\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     import argparse\n",
        "#     parser = argparse.ArgumentParser()\n",
        "#     parser.add_argument(\"--csv\", required=True, help=\"Path to Amazon Sale Report CSV\")\n",
        "#     parser.add_argument(\"--out\", default=\"analysis_outputs\", help=\"Output directory\")\n",
        "#     args = parser.parse_args()\n",
        "#     res = main(args.csv, args.out)\n",
        "#     print(\"Analysis complete. Outputs:\", res[\"outputs\"])\n",
        "#     print(\"Charts:\", res[\"charts\"])\n",
        "#     print(\"PPTX:\", res[\"pptx_path\"])\n",
        "\n",
        "# Call the main function directly with the CSV file path\n",
        "csv_file_path = \"/content/Amazon Sale Report.csv\"\n",
        "output_directory = \"analysis_outputs\"\n",
        "res = main(csv_file_path, output_directory)\n",
        "print(\"Analysis complete. Outputs:\", res[\"outputs\"])\n",
        "print(\"Charts:\", res[\"charts\"])\n",
        "print(\"PPTX:\", res[\"pptx_path\"])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
